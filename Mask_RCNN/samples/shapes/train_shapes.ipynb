{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 1\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: c:\\Breathing_Bag_Defect\\Mask_RCNN\\logs\\shapes20230426T1455\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_2:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_5:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_8:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/GatherV2_11:0\", shape=(None, 7, 7, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_classifier/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_2:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_1:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_5:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_1:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_2:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_8:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_2:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/sub_3:0\", shape=(None,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/GatherV2_11:0\", shape=(None, 14, 14, 256), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/roi_align_mask/concat_grad/Shape_3:0\", shape=(4,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape_1:0\", shape=(4092,), dtype=int32), values=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Reshape:0\", shape=(4092, 4), dtype=float32), dense_shape=Tensor(\"training/SGD/gradients/gradients/ROI/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - batch: 0.0000e+00 - size: 1.0000 - loss: 7.2346 - rpn_class_loss: 0.1787 - rpn_bbox_loss: 3.8377 - mrcnn_class_loss: 1.0134 - mrcnn_bbox_loss: 1.3423 - mrcnn_mask_loss: 0.8625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 26s 26s/step - batch: 0.0000e+00 - size: 1.0000 - loss: 7.2346 - rpn_class_loss: 0.1787 - rpn_bbox_loss: 3.8377 - mrcnn_class_loss: 1.0134 - mrcnn_bbox_loss: 1.3423 - mrcnn_mask_loss: 0.8625 - val_loss: 6.3422 - val_rpn_class_loss: 0.0906 - val_rpn_bbox_loss: 3.0762 - val_mrcnn_class_loss: 1.1501 - val_mrcnn_bbox_loss: 1.3594 - val_mrcnn_mask_loss: 0.6660\n"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "# model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "# model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 1. LR=0.0001\n",
      "\n",
      "Checkpoint Path: c:\\Breathing_Bag_Defect\\Mask_RCNN\\logs\\shapes20230426T1448\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "rpn_model              (Functional)\n",
      "anchors                (ConstLayer)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Fine tune all layers\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Passing layers=\"all\" trains all layers. You can also \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# pass a regular expression to select which layers to\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# train by name pattern.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mtrain(dataset_train, dataset_val, \n\u001b[0;32m      6\u001b[0m             learning_rate\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mLEARNING_RATE \u001b[39m/\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[0;32m      8\u001b[0m             layers\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mall\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Breathing_Bag_Defect\\Mask_RCNN\\mrcnn\\model.py:2347\u001b[0m, in \u001b[0;36mMaskRCNN.train\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[0;32m   2345\u001b[0m log(\u001b[39m\"\u001b[39m\u001b[39mCheckpoint Path: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_path))\n\u001b[0;32m   2346\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_trainable(layers)\n\u001b[1;32m-> 2347\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile(learning_rate, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mLEARNING_MOMENTUM)\n\u001b[0;32m   2349\u001b[0m \u001b[39m# Work-around for Windows: Keras fails on Windows when using\u001b[39;00m\n\u001b[0;32m   2350\u001b[0m \u001b[39m# multiprocessing workers. See discussion here:\u001b[39;00m\n\u001b[0;32m   2351\u001b[0m \u001b[39m# https://github.com/matterport/Mask_RCNN/issues/13#issuecomment-353124009\u001b[39;00m\n\u001b[0;32m   2352\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnt\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Breathing_Bag_Defect\\Mask_RCNN\\mrcnn\\model.py:2170\u001b[0m, in \u001b[0;36mMaskRCNN.compile\u001b[1;34m(self, learning_rate, momentum)\u001b[0m\n\u001b[0;32m   2166\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m   2167\u001b[0m     loss \u001b[39m=\u001b[39m (\n\u001b[0;32m   2168\u001b[0m         tf\u001b[39m.\u001b[39mreduce_mean(input_tensor\u001b[39m=\u001b[39mlayer\u001b[39m.\u001b[39moutput, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   2169\u001b[0m         \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mLOSS_WEIGHTS\u001b[39m.\u001b[39mget(name, \u001b[39m1.\u001b[39m))\n\u001b[1;32m-> 2170\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkeras_model\u001b[39m.\u001b[39;49madd_loss(loss)\n\u001b[0;32m   2172\u001b[0m \u001b[39m# Add L2 Regularization\u001b[39;00m\n\u001b[0;32m   2173\u001b[0m \u001b[39m# Skip gamma and beta weights of batch normalization layers.\u001b[39;00m\n\u001b[0;32m   2174\u001b[0m reg_losses \u001b[39m=\u001b[39m [\n\u001b[0;32m   2175\u001b[0m     keras\u001b[39m.\u001b[39mregularizers\u001b[39m.\u001b[39ml2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mWEIGHT_DECAY)(w) \u001b[39m/\u001b[39m tf\u001b[39m.\u001b[39mcast(tf\u001b[39m.\u001b[39msize(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mw), tf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m   2176\u001b[0m     \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeras_model\u001b[39m.\u001b[39mtrainable_weights\n\u001b[0;32m   2177\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m w\u001b[39m.\u001b[39mname \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mbeta\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m w\u001b[39m.\u001b[39mname]\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1098\u001b[0m, in \u001b[0;36mLayer.add_loss\u001b[1;34m(self, losses, inputs)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[39mfor\u001b[39;00m symbolic_loss \u001b[39min\u001b[39;00m symbolic_losses:\n\u001b[0;32m   1097\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_is_graph_network\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph_network_add_loss(symbolic_loss)\n\u001b[0;32m   1099\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[39m# Possible a loss was added in a Layer's `build`.\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_losses\u001b[39m.\u001b[39mappend(symbolic_loss)\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:849\u001b[0m, in \u001b[0;36mFunctional._graph_network_add_loss\u001b[1;34m(self, symbolic_loss)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_graph_network_add_loss\u001b[39m(\u001b[39mself\u001b[39m, symbolic_loss):\n\u001b[1;32m--> 849\u001b[0m   new_nodes, new_layers \u001b[39m=\u001b[39m _map_subgraph_network(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs, [symbolic_loss])\n\u001b[0;32m    850\u001b[0m   \u001b[39m# Losses must be keyed on inputs no matter what in order to be supported in\u001b[39;00m\n\u001b[0;32m    851\u001b[0m   \u001b[39m# DistributionStrategy.\u001b[39;00m\n\u001b[0;32m    852\u001b[0m   add_loss_layer \u001b[39m=\u001b[39m base_layer\u001b[39m.\u001b[39mAddLoss(\n\u001b[0;32m    853\u001b[0m       unconditional\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39msymbolic_loss\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:1079\u001b[0m, in \u001b[0;36m_map_subgraph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the nodes and layers in the topology from `inputs` to `outputs`.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \n\u001b[0;32m   1071\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39m  A tuple of List{Node] and List[Layer].\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m keras_tensor\u001b[39m.\u001b[39mkeras_tensors_enabled():\n\u001b[1;32m-> 1079\u001b[0m   base_layer_utils\u001b[39m.\u001b[39;49mcreate_keras_history(outputs)\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Keep only nodes and layers in the topology between inputs and outputs.\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m _, nodes_by_depth, layers, _ \u001b[39m=\u001b[39m _map_graph_network(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:188\u001b[0m, in \u001b[0;36mcreate_keras_history\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_keras_history\u001b[39m(tensors):\n\u001b[0;32m    170\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Wraps TensorFlow Operations for compatibility with the Functional API.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \n\u001b[0;32m    172\u001b[0m \u001b[39m  This method checks to see if a Tensor in `tensors` is missing Keras metadata\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[39m      the raw Tensorflow operations.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m   _, created_layers \u001b[39m=\u001b[39m _create_keras_history_helper(tensors, \u001b[39mset\u001b[39;49m(), [])\n\u001b[0;32m    189\u001b[0m   \u001b[39mreturn\u001b[39;00m created_layers\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:252\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    250\u001b[0m           constants[i] \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mfunction([], op_input)([])\n\u001b[0;32m    251\u001b[0m layer_inputs \u001b[39m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[1;32m--> 252\u001b[0m processed_ops, created_layers \u001b[39m=\u001b[39m _create_keras_history_helper(\n\u001b[0;32m    253\u001b[0m     layer_inputs, processed_ops, created_layers)\n\u001b[0;32m    254\u001b[0m name \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39mname\n\u001b[0;32m    255\u001b[0m node_def \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39mnode_def\u001b[39m.\u001b[39mSerializeToString()\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:250\u001b[0m, in \u001b[0;36m_create_keras_history_helper\u001b[1;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[0;32m    248\u001b[0m           constants[i] \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39meval_in_eager_or_function(op_input)\n\u001b[0;32m    249\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m           constants[i] \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mfunction([], op_input)([])\n\u001b[0;32m    251\u001b[0m layer_inputs \u001b[39m=\u001b[39m unnest_if_single_tensor(layer_inputs)\n\u001b[0;32m    252\u001b[0m processed_ops, created_layers \u001b[39m=\u001b[39m _create_keras_history_helper(\n\u001b[0;32m    253\u001b[0m     layer_inputs, processed_ops, created_layers)\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:3954\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3949\u001b[0m \u001b[39m# Refresh callable if anything has changed.\u001b[39;00m\n\u001b[0;32m   3950\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m feed_arrays \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feed_arrays \u001b[39mor\u001b[39;00m\n\u001b[0;32m   3951\u001b[0m     symbol_vals \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_symbol_vals \u001b[39mor\u001b[39;00m\n\u001b[0;32m   3952\u001b[0m     feed_symbols \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feed_symbols \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfetches \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetches \u001b[39mor\u001b[39;00m\n\u001b[0;32m   3953\u001b[0m     session \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session):\n\u001b[1;32m-> 3954\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m   3956\u001b[0m fetched \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable_fn(\u001b[39m*\u001b[39marray_vals,\n\u001b[0;32m   3957\u001b[0m                             run_metadata\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_metadata)\n\u001b[0;32m   3958\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetches):])\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:3890\u001b[0m, in \u001b[0;36mGraphExecutionFunction._make_callable\u001b[1;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[0;32m   3888\u001b[0m   callable_opts\u001b[39m.\u001b[39mrun_options\u001b[39m.\u001b[39mCopyFrom(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_options)\n\u001b[0;32m   3889\u001b[0m \u001b[39m# Create callable.\u001b[39;00m\n\u001b[1;32m-> 3890\u001b[0m callable_fn \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49m_make_callable_from_options(callable_opts)\n\u001b[0;32m   3891\u001b[0m \u001b[39m# Cache parameters corresponding to the generated callable, so that\u001b[39;00m\n\u001b[0;32m   3892\u001b[0m \u001b[39m# we can detect future mismatches and refresh the callable.\u001b[39;00m\n\u001b[0;32m   3893\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable_fn \u001b[39m=\u001b[39m callable_fn\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1514\u001b[0m, in \u001b[0;36mBaseSession._make_callable_from_options\u001b[1;34m(self, callable_options)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_callable_from_options\u001b[39m(\u001b[39mself\u001b[39m, callable_options):\n\u001b[0;32m   1505\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a handle to a \"callable\" with the given options.\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \n\u001b[0;32m   1507\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[39m    A handle to the new callable.\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1514\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extend_graph()\n\u001b[0;32m   1515\u001b[0m   \u001b[39mreturn\u001b[39;00m BaseSession\u001b[39m.\u001b[39m_Callable(\u001b[39mself\u001b[39m, callable_options)\n",
      "File \u001b[1;32mc:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1398\u001b[0m, in \u001b[0;36mBaseSession._extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_extend_graph\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1397\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_session_run_lock():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1398\u001b[0m     tf_session\u001b[39m.\u001b[39;49mExtendSession(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Tools\\anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Loading weights from  c:\\Breathing_Bag_Defect\\Mask_RCNN\\logs\\shapes20230426T1455\\mask_rcnn_shapes_0001.h5\n",
      "Re-starting from epoch 1\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_image           shape: (128, 128, 3)         min:   12.00000  max:  251.00000  uint8\n",
      "image_meta               shape: (16,)                 min:    0.00000  max:  128.00000  int32\n",
      "gt_class_id              shape: (2,)                  min:    1.00000  max:    3.00000  int32\n",
      "gt_bbox                  shape: (2, 4)                min:    4.00000  max:  118.00000  int32\n",
      "gt_mask                  shape: (56, 56, 2)           min:    0.00000  max:    1.00000  bool\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (56,56) (128,128) (128,128) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m log(\u001b[39m\"\u001b[39m\u001b[39mgt_bbox\u001b[39m\u001b[39m\"\u001b[39m, gt_bbox)\n\u001b[0;32m     11\u001b[0m log(\u001b[39m\"\u001b[39m\u001b[39mgt_mask\u001b[39m\u001b[39m\"\u001b[39m, gt_mask)\n\u001b[1;32m---> 13\u001b[0m visualize\u001b[39m.\u001b[39;49mdisplay_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n\u001b[0;32m     14\u001b[0m                             dataset_train\u001b[39m.\u001b[39;49mclass_names, figsize\u001b[39m=\u001b[39;49m(\u001b[39m8\u001b[39;49m, \u001b[39m8\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Breathing_Bag_Defect\\Mask_RCNN\\mrcnn\\visualize.py:152\u001b[0m, in \u001b[0;36mdisplay_instances\u001b[1;34m(image, boxes, masks, class_ids, class_names, scores, title, figsize, ax, show_mask, show_bbox, colors, captions)\u001b[0m\n\u001b[0;32m    150\u001b[0m mask \u001b[39m=\u001b[39m masks[:, :, i]\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m show_mask:\n\u001b[1;32m--> 152\u001b[0m     masked_image \u001b[39m=\u001b[39m apply_mask(masked_image, mask, color)\n\u001b[0;32m    154\u001b[0m \u001b[39m# Mask Polygon\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39m# Pad to ensure proper polygons for masks that touch image edges.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m padded_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\n\u001b[0;32m    157\u001b[0m     (mask\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m, mask\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39muint8)\n",
      "File \u001b[1;32mc:\\Breathing_Bag_Defect\\Mask_RCNN\\mrcnn\\visualize.py:76\u001b[0m, in \u001b[0;36mapply_mask\u001b[1;34m(image, mask, color, alpha)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Apply the given mask to the image.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m---> 76\u001b[0m     image[:, :, c] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mwhere(mask \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     77\u001b[0m                               image[:, :, c] \u001b[39m*\u001b[39;49m\n\u001b[0;32m     78\u001b[0m                               (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m alpha) \u001b[39m+\u001b[39;49m alpha \u001b[39m*\u001b[39;49m color[c] \u001b[39m*\u001b[39;49m \u001b[39m255\u001b[39;49m,\n\u001b[0;32m     79\u001b[0m                               image[:, :, c])\n\u001b[0;32m     80\u001b[0m \u001b[39mreturn\u001b[39;00m image\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (56,56) (128,128) (128,128) "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_image_gt() got an unexpected keyword argument 'USE_MINI_MASK'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m APs \u001b[39m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m image_id \u001b[39min\u001b[39;00m image_ids:\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Load image and ground truth data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     image, image_meta, gt_class_id, gt_bbox, gt_mask \u001b[39m=\u001b[39m\\\n\u001b[1;32m----> 8\u001b[0m         modellib\u001b[39m.\u001b[39;49mload_image_gt(dataset_val, inference_config,\n\u001b[0;32m      9\u001b[0m                                image_id, USE_MINI_MASK\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     10\u001b[0m     molded_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(modellib\u001b[39m.\u001b[39mmold_image(image, inference_config), \u001b[39m0\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[39m# Run object detection\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: load_image_gt() got an unexpected keyword argument 'USE_MINI_MASK'"
     ]
    }
   ],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
